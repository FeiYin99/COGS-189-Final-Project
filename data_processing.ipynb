{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e94167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import butter, sosfiltfilt, sosfreqz  \n",
    "from scipy.io import loadmat\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66d6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For visualization\n",
    "import PyQt5\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232ab80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define directories\n",
    "data_dir = '/home/inffzy/Desktop/cogs189/cogs189_final_project/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903667cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Raw data directory names\n",
    "bc3_3a_raw_name = 'bci_competition_3_3a_raw'\n",
    "bc3_4a_raw_name = 'bci_competition_3_4a_raw'\n",
    "bc4_2a_raw_name = 'bci_competition_4_2a_raw'\n",
    "\n",
    "bc3_3a_processed_name = 'bci_competition_3_3a_processed'\n",
    "bc3_4a_processed_name = 'bci_competition_3_4a_processed'\n",
    "bc4_2a_processed_name = 'bci_competition_4_2a_processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0048e9d2",
   "metadata": {},
   "source": [
    "## Process BCI Competition Dataset 4_2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03427a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define directory\n",
    "bc4_2a_raw_dir = os.path.join(data_dir, bc4_2a_raw_name)\n",
    "bc4_2a_processed_dir = os.path.join(data_dir, bc4_2a_processed_name)\n",
    "\n",
    "if not os.path.isdir(bc4_2a_processed_dir):\n",
    "    os.mkdir(bc4_2a_processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6207f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "num_subjects = 9\n",
    "num_channels = 25\n",
    "sampling_f = 250  ## Hz\n",
    "baseline_duration = 2  ## seconds\n",
    "motor_imagery_start = 3  ## seconds after trial begins\n",
    "motor_imagery_end = 6  ## seconds after trial begins\n",
    "motor_imagery_trial_duration = motor_imagery_end - motor_imagery_start  ## seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create filter\n",
    "order = 6\n",
    "lower_passband = 7\n",
    "upper_passband = 30\n",
    "sos = butter(order, \n",
    "             [lower_passband, upper_passband], \n",
    "             analog = False, \n",
    "             btype = 'band', \n",
    "             output = 'sos', \n",
    "             fs = sampling_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_subject in range(1, 10):\n",
    "    \n",
    "    ## Load subject dataset with MNE\n",
    "    subject_name = 'A0' + str(idx_subject) + 'T'\n",
    "    subject_path = os.path.join(bc4_2a_raw_dir, subject_name + '.gdf')\n",
    "    subject_mne = mne.io.read_raw_gdf(subject_path)\n",
    "    raw_data = subject_mne.get_data()\n",
    "    \n",
    "    ## Access annotations\n",
    "    annotations = subject_mne.annotations\n",
    "    annotations_list = list(annotations)\n",
    "    \n",
    "    ## Convert annotation dictionary into lists\n",
    "    descriptions = []\n",
    "    onsets = []\n",
    "\n",
    "    for i in range(len(annotations_list) - 1):\n",
    "        \n",
    "        description_cur = annotations_list[i]['description']\n",
    "        description_next = annotations_list[i + 1]['description']\n",
    "        \n",
    "        ## Check if the current trial is valid and has a known cue\n",
    "        if description_cur == '768' and description_next in ['769', '770', '771', '772']:    \n",
    "            onsets.append(annotations_list[i]['onset'])\n",
    "            descriptions.append(int(description_next))\n",
    "    \n",
    "    descriptions = np.array(descriptions)\n",
    "    onsets = np.array(onsets)\n",
    "    \n",
    "    ## Process by onsets to create epochs\n",
    "    num_valid_trials = onsets.shape[0]\n",
    "\n",
    "    ## Initialize processed data array\n",
    "    processed_motor_imagery_data = np.zeros((num_valid_trials, \n",
    "                                             num_channels, \n",
    "                                             motor_imagery_trial_duration * sampling_f))\n",
    "    \n",
    "    for idx_trial in range(num_valid_trials):\n",
    "        \n",
    "        ## Epoching\n",
    "        onset_time = onsets[idx_trial]\n",
    "        onset_index = int(onset_time * sampling_f)\n",
    "        \n",
    "        motor_imagery_start_time = onset_time + motor_imagery_start        \n",
    "        motor_imagery_start_index = int(motor_imagery_start_time * sampling_f)\n",
    "        motor_imagery_end_index = motor_imagery_start_index + motor_imagery_trial_duration * sampling_f\n",
    "        \n",
    "        motor_imagery_data = raw_data[:, motor_imagery_start_index:motor_imagery_end_index]\n",
    "        \n",
    "        ## DC correction\n",
    "        motor_imagery_data_mean = np.mean(motor_imagery_data, axis=1).reshape((num_channels, 1))\n",
    "        motor_imagery_data = motor_imagery_data - motor_imagery_data_mean\n",
    "        \n",
    "        ## Filtering (band pass to 7~30 Hz)\n",
    "        motor_imagery_data = sosfiltfilt(sos, motor_imagery_data, axis=1)\n",
    "        \n",
    "        ## Baseline correction\n",
    "        baseline_end_index = onset_index + baseline_duration * sampling_f\n",
    "        \n",
    "        baseline_data = raw_data[:, onset_index:baseline_end_index]\n",
    "        baseline_data_mean = np.mean(baseline_data, axis=1).reshape((num_channels, 1))\n",
    "        motor_imagery_data = motor_imagery_data - baseline_data_mean\n",
    "        \n",
    "        ## Store processed motor imagery data\n",
    "        processed_motor_imagery_data[idx_trial, :, :] = motor_imagery_data\n",
    "    \n",
    "    \n",
    "    ## Export processed motor imagery data\n",
    "    processed_subject_path = os.path.join(bc4_2a_processed_dir, subject_name + '.npz')\n",
    "    np.savez(processed_subject_path, \n",
    "             processed_motor_imagery_data=processed_motor_imagery_data, \n",
    "             descriptions=descriptions, \n",
    "             onsets=onsets)\n",
    "    \n",
    "    print('Finished processing subject dataset ', idx_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d50ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify processed data\n",
    "processed_dataset_path = os.path.join(bc4_2a_processed_dir, 'A01T.npz')\n",
    "processed_dataset_npz = np.load(processed_dataset_path)\n",
    "print(processed_dataset_npz.files)\n",
    "print(processed_dataset_npz['processed_motor_imagery_data'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74673434",
   "metadata": {},
   "source": [
    "## Process BCI Competition Dataset 3_3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "118032bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define directory\n",
    "bc3_3a_raw_dir = os.path.join(data_dir, bc3_3a_raw_name)\n",
    "bc3_3a_processed_dir = os.path.join(data_dir, bc3_3a_processed_name)\n",
    "\n",
    "if not os.path.isdir(bc3_3a_processed_dir):\n",
    "    os.mkdir(bc3_3a_processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2c449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "num_subjects = 3\n",
    "num_channels = 60\n",
    "sampling_f = 250  ## Hz\n",
    "baseline_duration = 2  ## seconds\n",
    "motor_imagery_start = 4  ## seconds after trial begins\n",
    "motor_imagery_end = 7  ## seconds after trial begins\n",
    "motor_imagery_trial_duration = motor_imagery_end - motor_imagery_start  ## seconds\n",
    "\n",
    "## Note: for the 3_3a dataset, the training time span is technically 3s to 7s.\n",
    "##   but since no break is given, and reaction time is not accounted for, we use 3.5s to 6.5s, \n",
    "##   making a duration of 3s, same as 4_2a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c00984",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create filter\n",
    "order = 6\n",
    "lower_passband = 7\n",
    "upper_passband = 30\n",
    "sos = butter(order, \n",
    "             [lower_passband, upper_passband], \n",
    "             analog = False, \n",
    "             btype = 'band', \n",
    "             output = 'sos', \n",
    "             fs = sampling_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f5450c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_3_3a_raw/subject1_k3b/bc3_3a_s1.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "#  1, #  2, #  3, #  4, #  5, #  6, #  7, #  8, #  9, # 10, # 11, # 12, # 13, # 14, # 15, # 16, # 17, # 18, # 19, # 20, # 21, # 22, # 23, # 24, # 25, # 26, # 27, # 28, # 29, # 30, # 31, # 32, # 33, # 34, # 35, # 36, # 37, # 38, # 39, # 40, # 41, # 42, # 43, # 44, # 45, # 46, # 47, # 48, # 49, # 50, # 51, # 52, # 53, # 54, # 55, # 56, # 57, # 58, # 59, # 60\n",
      "Creating raw.info structure...\n",
      "Finished processing annotation for subject 1\n",
      "\tTotoal trial count:  360\n",
      "\tRejected trial count:  62\n",
      "\tUnknown cue count:  149\n",
      "\tNumber of valid trials:  149\n",
      "Finished processing subject dataset  1\n",
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_3_3a_raw/subject2_k6b/bc3_3a_s2.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "#  1, #  2, #  3, #  4, #  5, #  6, #  7, #  8, #  9, # 10, # 11, # 12, # 13, # 14, # 15, # 16, # 17, # 18, # 19, # 20, # 21, # 22, # 23, # 24, # 25, # 26, # 27, # 28, # 29, # 30, # 31, # 32, # 33, # 34, # 35, # 36, # 37, # 38, # 39, # 40, # 41, # 42, # 43, # 44, # 45, # 46, # 47, # 48, # 49, # 50, # 51, # 52, # 53, # 54, # 55, # 56, # 57, # 58, # 59, # 60\n",
      "Creating raw.info structure...\n",
      "Finished processing annotation for subject 2\n",
      "\tTotoal trial count:  240\n",
      "\tRejected trial count:  65\n",
      "\tUnknown cue count:  83\n",
      "\tNumber of valid trials:  92\n",
      "Finished processing subject dataset  2\n",
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_3_3a_raw/subject3_l1b/bc3_3a_s3.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "#  1, #  2, #  3, #  4, #  5, #  6, #  7, #  8, #  9, # 10, # 11, # 12, # 13, # 14, # 15, # 16, # 17, # 18, # 19, # 20, # 21, # 22, # 23, # 24, # 25, # 26, # 27, # 28, # 29, # 30, # 31, # 32, # 33, # 34, # 35, # 36, # 37, # 38, # 39, # 40, # 41, # 42, # 43, # 44, # 45, # 46, # 47, # 48, # 49, # 50, # 51, # 52, # 53, # 54, # 55, # 56, # 57, # 58, # 59, # 60\n",
      "Creating raw.info structure...\n",
      "Finished processing annotation for subject 3\n",
      "\tTotoal trial count:  240\n",
      "\tRejected trial count:  73\n",
      "\tUnknown cue count:  83\n",
      "\tNumber of valid trials:  84\n",
      "Finished processing subject dataset  3\n"
     ]
    }
   ],
   "source": [
    "subject_dir_names = ['subject1_k3b', 'subject2_k6b', 'subject3_l1b']\n",
    "\n",
    "\n",
    "for idx_subject, subject_dir_name in enumerate(subject_dir_names):\n",
    "    idx_subject += 1\n",
    "    \n",
    "    ## Load subject dataset with MNE\n",
    "    subject_dir = os.path.join(bc3_3a_raw_dir, subject_dir_name)\n",
    "    subject_name = 'bc3_3a_s' + str(idx_subject)\n",
    "    subject_path_gdf = os.path.join(subject_dir, subject_name + '.gdf')\n",
    "    subject_mne = mne.io.read_raw_gdf(subject_path_gdf)\n",
    "    raw_data = subject_mne.get_data()\n",
    "    \n",
    "    ## Access annotations\n",
    "    annotations = subject_mne.annotations\n",
    "    annotations_list = list(annotations)\n",
    "    \n",
    "    ## Convert annotation dictionary into lists\n",
    "    descriptions = []\n",
    "    onsets = []\n",
    "    onset_trial = -1\n",
    "    valid_trial = True\n",
    "    total_trial_count = 0\n",
    "    rejected_trial_count = 0\n",
    "    unknown_cue_count = 0\n",
    "    \n",
    "    for i in range(len(annotations_list)):\n",
    "        \n",
    "        description_cur = annotations_list[i]['description']\n",
    "        onset_cur = annotations_list[i]['onset']\n",
    "        \n",
    "        if description_cur == '768':\n",
    "            valid_trial = True\n",
    "            onset_trial = onset_cur\n",
    "            total_trial_count += 1\n",
    "            \n",
    "        elif description_cur == '1023':\n",
    "            valid_trial = False\n",
    "            rejected_trial_count += 1\n",
    "            \n",
    "        elif valid_trial: \n",
    "            if description_cur in ['769', '770', '771', '772']:\n",
    "                descriptions.append(description_cur)\n",
    "                onsets.append(onset_trial)\n",
    "            elif description_cur == '783':\n",
    "                unknown_cue_count += 1\n",
    "            \n",
    "    descriptions = np.array(descriptions)\n",
    "    onsets = np.array(onsets)\n",
    "    num_valid_trials = onsets.shape[0]\n",
    "    \n",
    "    print('Finished processing annotation for subject', idx_subject)\n",
    "    print('\\tTotoal trial count: ', total_trial_count)\n",
    "    print('\\tRejected trial count: ', rejected_trial_count)\n",
    "    print('\\tUnknown cue count: ', unknown_cue_count)\n",
    "    print('\\tNumber of valid trials: ', num_valid_trials)\n",
    "    \n",
    "    ## Process by onsets to create epochs\n",
    "    \n",
    "    ## Initialize processed data array\n",
    "    processed_motor_imagery_data = np.zeros((num_valid_trials, \n",
    "                                             num_channels, \n",
    "                                             int(motor_imagery_trial_duration * sampling_f)))\n",
    "    \n",
    "    for idx_trial in range(num_valid_trials):\n",
    "        \n",
    "        ## Epoching\n",
    "        onset_time = onsets[idx_trial]\n",
    "        onset_index = int(onset_time * sampling_f)\n",
    "        \n",
    "        motor_imagery_start_time = onset_time + motor_imagery_start        \n",
    "        motor_imagery_start_index = int(motor_imagery_start_time * sampling_f)\n",
    "        motor_imagery_end_index = motor_imagery_start_index + int(motor_imagery_trial_duration * sampling_f)\n",
    "      \n",
    "        motor_imagery_data = raw_data[:, motor_imagery_start_index:motor_imagery_end_index]\n",
    "        \n",
    "        ## DC correction\n",
    "        motor_imagery_data_mean = np.mean(motor_imagery_data, axis=1).reshape((num_channels, 1))\n",
    "        motor_imagery_data = motor_imagery_data - motor_imagery_data_mean\n",
    "        \n",
    "        ## Filtering (band pass to 7~30 Hz)\n",
    "        motor_imagery_data = sosfiltfilt(sos, motor_imagery_data, axis=1)\n",
    "        \n",
    "        ## Baseline correction\n",
    "        baseline_end_index = onset_index + baseline_duration * sampling_f\n",
    "        \n",
    "        baseline_data = raw_data[:, onset_index:baseline_end_index]\n",
    "        baseline_data_mean = np.mean(baseline_data, axis=1).reshape((num_channels, 1))\n",
    "        motor_imagery_data = motor_imagery_data - baseline_data_mean\n",
    "        \n",
    "        ## Store processed motor imagery data\n",
    "        processed_motor_imagery_data[idx_trial, :, :] = motor_imagery_data\n",
    "    \n",
    "    \n",
    "    ## Export processed motor imagery data\n",
    "    processed_subject_path = os.path.join(bc3_3a_processed_dir, subject_name + '.npz')\n",
    "    np.savez(processed_subject_path, \n",
    "             processed_motor_imagery_data=processed_motor_imagery_data, \n",
    "             descriptions=descriptions, \n",
    "             onsets=onsets)\n",
    "    \n",
    "    print('Finished processing subject dataset ', idx_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f686062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['processed_motor_imagery_data', 'descriptions', 'onsets']\n",
      "(149, 60, 750)\n"
     ]
    }
   ],
   "source": [
    "## Verify processed data\n",
    "processed_dataset_path = os.path.join(bc3_3a_processed_dir, 'bc3_3a_s1.npz')\n",
    "processed_dataset_npz = np.load(processed_dataset_path)\n",
    "print(processed_dataset_npz.files)\n",
    "print(processed_dataset_npz['processed_motor_imagery_data'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881d522e",
   "metadata": {},
   "source": [
    "## Process BCI Competition Dataset 3_4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff77100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaffea8c",
   "metadata": {},
   "source": [
    "## Explore BCI Competition Dataset 4_2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine A01T.gdf with MNE\n",
    "bc4_2a_raw_dir = os.path.join(data_dir, bc4_2a_raw_name)\n",
    "A01T_path = os.path.join(bc4_2a_raw_dir, 'A01T.gdf')\n",
    "A01T = mne.io.read_raw_gdf(A01T_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A01T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print channel names\n",
    "A01T.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a3a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print raw data and shape\n",
    "A01T_raw_data = A01T.get_data()\n",
    "print(A01T_raw_data)\n",
    "print(A01T_raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be7912",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize data\n",
    "A01T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine annotations\n",
    "A01T_annotations = A01T.annotations\n",
    "A01T_annotations_list = list(A01T_annotations)\n",
    "A01T_annotations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert annotation dictionary into lists\n",
    "A01T_trial_onsets = []\n",
    "A01T_trial_durations = []\n",
    "A01T_trial_descriptions = []\n",
    "\n",
    "for i in range(len(A01T_annotations_list) - 1):\n",
    "    \n",
    "    description_cur = A01T_annotations_list[i]['description']\n",
    "    description_next = A01T_annotations_list[i + 1]['description']\n",
    "    \n",
    "    ## Check if the current trial is valid and has a known cue\n",
    "    if description_cur == '768' and description_next in ['769', '770', '771', '772']:    \n",
    "        A01T_trial_onsets.append(A01T_annotations_list[i]['onset'])\n",
    "        A01T_trial_durations.append(A01T_annotations_list[i]['duration'])\n",
    "        A01T_trial_descriptions.append(int(description_next))\n",
    "\n",
    "        \n",
    "A01T_trial_descriptions = np.array(A01T_trial_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bded7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A01T_trial_descriptions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
