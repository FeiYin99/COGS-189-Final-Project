{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e9c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import butter, sosfiltfilt, sosfreqz  \n",
    "from scipy.io import loadmat\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "879674fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "bc4_2a_raw_name = 'bci_competition_4_2a_raw'\n",
    "bc3_3a_raw_name = 'bci_competition_3_3a_raw'\n",
    "\n",
    "bc4_2a_processed_name = 'bci_competition_4_2a_processed'\n",
    "bc3_3a_processed_name = 'bci_competition_3_3a_processed'\n",
    "\n",
    "bc4_2a_raw_dir = os.path.join(data_dir, bc4_2a_raw_name)\n",
    "bc4_2a_processed_dir = os.path.join(data_dir, bc4_2a_processed_name)\n",
    "\n",
    "bc3_3a_raw_dir = os.path.join(data_dir, bc3_3a_raw_name)\n",
    "bc3_3a_processed_dir = os.path.join(data_dir, bc3_3a_processed_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eab543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "num_subjects = 9\n",
    "num_channels = 22\n",
    "sampling_f = 250  ## Hz\n",
    "baseline_duration = 2  ## seconds\n",
    "motor_imagery_start = 3.5  ## seconds after trial begins\n",
    "motor_imagery_end = 5.5  ## seconds after trial begins\n",
    "motor_imagery_trial_duration = int(motor_imagery_end - motor_imagery_start)  ## seconds\n",
    "\n",
    "## Create filter\n",
    "order = 6\n",
    "lower_passband = 7\n",
    "upper_passband = 30\n",
    "sos = butter(order, \n",
    "             [lower_passband, upper_passband], \n",
    "             analog = False, \n",
    "             btype = 'band', \n",
    "             output = 'sos', \n",
    "             fs = sampling_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2715e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_4_2a_raw/A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/site-packages/mne/io/edf/edf.py:1131: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing subject dataset  1\n",
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_4_2a_raw/A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/site-packages/mne/io/edf/edf.py:1131: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing subject dataset  2\n",
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_4_2a_raw/A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/site-packages/mne/io/edf/edf.py:1131: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing subject dataset  3\n",
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_4_2a_raw/A04T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/site-packages/mne/io/edf/edf.py:1131: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing subject dataset  4\n",
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_4_2a_raw/A05T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/site-packages/mne/io/edf/edf.py:1131: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing subject dataset  5\n",
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_4_2a_raw/A06T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/site-packages/mne/io/edf/edf.py:1131: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing subject dataset  6\n",
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_4_2a_raw/A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/site-packages/mne/io/edf/edf.py:1131: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing subject dataset  7\n",
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_4_2a_raw/A08T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/site-packages/mne/io/edf/edf.py:1131: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing subject dataset  8\n",
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_4_2a_raw/A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/site-packages/mne/io/edf/edf.py:1131: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "/home/inffzy/.conda/envs/cogs189/lib/python3.9/contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing subject dataset  9\n"
     ]
    }
   ],
   "source": [
    "for idx_subject in range(1, 10):\n",
    "\n",
    "    subject_name = 'A0' + str(idx_subject) + 'T'\n",
    "    subject_path = os.path.join(bc4_2a_raw_dir, subject_name + '.gdf')\n",
    "    subject_mne = mne.io.read_raw_gdf(subject_path)\n",
    "    raw_data = subject_mne.get_data()[:22]\n",
    "    \n",
    "    X = raw_data.T  # Observations (mixed signal)\n",
    "    ica = FastICA(n_components=22)\n",
    "    S_ = ica.fit_transform(X)  # Recovered signals\n",
    "    A_ = ica.mixing_  # Get estimated mixing matrix\n",
    "    raw_data = S_.T\n",
    "    \n",
    "    \n",
    "    ## Access annotations\n",
    "    annotations = subject_mne.annotations\n",
    "    annotations_list = list(annotations)\n",
    "    \n",
    "    ## Convert annotation dictionary into lists\n",
    "    descriptions = []\n",
    "    onsets = []\n",
    "\n",
    "    for i in range(len(annotations_list) - 1):\n",
    "        \n",
    "        description_cur = annotations_list[i]['description']\n",
    "        description_next = annotations_list[i + 1]['description']\n",
    "        \n",
    "        ## Check if the current trial is valid and has a known cue\n",
    "        if description_cur == '768' and description_next in ['769', '770', '771', '772']:    \n",
    "            onsets.append(annotations_list[i]['onset'])\n",
    "            descriptions.append(int(description_next))\n",
    "    \n",
    "    descriptions = np.array(descriptions)\n",
    "    onsets = np.array(onsets)\n",
    "    \n",
    "    ## Process by onsets to create epochs\n",
    "    num_valid_trials = onsets.shape[0]\n",
    "\n",
    "    ## Initialize processed data array\n",
    "    processed_motor_imagery_data = np.zeros((num_valid_trials,\n",
    "                                             num_channels,\n",
    "                                             motor_imagery_trial_duration * sampling_f))\n",
    "    \n",
    "    for idx_trial in range(num_valid_trials):\n",
    "        \n",
    "        ## Epoching\n",
    "        onset_time = onsets[idx_trial]\n",
    "        onset_index = int(onset_time * sampling_f)\n",
    "        \n",
    "        motor_imagery_start_time = onset_time + motor_imagery_start        \n",
    "        motor_imagery_start_index = int(motor_imagery_start_time * sampling_f)\n",
    "        motor_imagery_end_index = motor_imagery_start_index + motor_imagery_trial_duration * sampling_f\n",
    "        \n",
    "        motor_imagery_data = raw_data[:, motor_imagery_start_index:motor_imagery_end_index]\n",
    "        \n",
    "        ## DC correction\n",
    "        motor_imagery_data_mean = np.mean(motor_imagery_data, axis=1).reshape((num_channels, 1))\n",
    "        motor_imagery_data = motor_imagery_data - motor_imagery_data_mean\n",
    "        \n",
    "        ## Filtering (band pass to 7~30 Hz)\n",
    "        motor_imagery_data = sosfiltfilt(sos, motor_imagery_data, axis=1)\n",
    "        \n",
    "        ## Baseline correction\n",
    "        baseline_end_index = onset_index + baseline_duration * sampling_f\n",
    "        \n",
    "        baseline_data = raw_data[:, onset_index:baseline_end_index]\n",
    "        baseline_data_mean = np.mean(baseline_data, axis=1).reshape((num_channels, 1))\n",
    "        motor_imagery_data = motor_imagery_data - baseline_data_mean\n",
    "        \n",
    "        ## Store processed motor imagery data\n",
    "        processed_motor_imagery_data[idx_trial, :, :] = motor_imagery_data\n",
    "    \n",
    "    \n",
    "    ## Export processed motor imagery data\n",
    "    processed_subject_path = os.path.join(bc4_2a_processed_dir, subject_name + '_ica.npz')\n",
    "    np.savez(processed_subject_path, \n",
    "             processed_motor_imagery_data=processed_motor_imagery_data, \n",
    "             descriptions=descriptions, \n",
    "             onsets=onsets)\n",
    "    \n",
    "    print('Finished processing subject dataset ', idx_subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e99217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "num_subjects = 3\n",
    "num_channels = 60\n",
    "sampling_f = 250  ## Hz\n",
    "baseline_duration = 2  ## seconds\n",
    "motor_imagery_start = 4.5  ## seconds after trial begins\n",
    "motor_imagery_end = 6.5  ## seconds after trial begins\n",
    "motor_imagery_trial_duration = int(motor_imagery_end - motor_imagery_start)  ## seconds\n",
    "\n",
    "## Note: for the 3_3a dataset, the training time span is technically 3s to 7s.\n",
    "##   but since no break is given, and reaction time is not accounted for, we use 4.5s to 6.5s, \n",
    "##   making a duration of 2s, same as 4_2a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e732b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create filter\n",
    "order = 6\n",
    "lower_passband = 7\n",
    "upper_passband = 30\n",
    "sos = butter(order, \n",
    "             [lower_passband, upper_passband], \n",
    "             analog = False, \n",
    "             btype = 'band', \n",
    "             output = 'sos', \n",
    "             fs = sampling_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa77832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_3_3a_raw/subject1_k3b/bc3_3a_s1.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "#  1, #  2, #  3, #  4, #  5, #  6, #  7, #  8, #  9, # 10, # 11, # 12, # 13, # 14, # 15, # 16, # 17, # 18, # 19, # 20, # 21, # 22, # 23, # 24, # 25, # 26, # 27, # 28, # 29, # 30, # 31, # 32, # 33, # 34, # 35, # 36, # 37, # 38, # 39, # 40, # 41, # 42, # 43, # 44, # 45, # 46, # 47, # 48, # 49, # 50, # 51, # 52, # 53, # 54, # 55, # 56, # 57, # 58, # 59, # 60\n",
      "Creating raw.info structure...\n",
      "Finished processing annotation for subject 1\n",
      "\tTotoal trial count:  360\n",
      "\tRejected trial count:  62\n",
      "\tUnknown cue count:  149\n",
      "\tNumber of valid trials:  149\n",
      "Finished processing subject dataset  1\n",
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_3_3a_raw/subject2_k6b/bc3_3a_s2.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "#  1, #  2, #  3, #  4, #  5, #  6, #  7, #  8, #  9, # 10, # 11, # 12, # 13, # 14, # 15, # 16, # 17, # 18, # 19, # 20, # 21, # 22, # 23, # 24, # 25, # 26, # 27, # 28, # 29, # 30, # 31, # 32, # 33, # 34, # 35, # 36, # 37, # 38, # 39, # 40, # 41, # 42, # 43, # 44, # 45, # 46, # 47, # 48, # 49, # 50, # 51, # 52, # 53, # 54, # 55, # 56, # 57, # 58, # 59, # 60\n",
      "Creating raw.info structure...\n",
      "Finished processing annotation for subject 2\n",
      "\tTotoal trial count:  240\n",
      "\tRejected trial count:  65\n",
      "\tUnknown cue count:  83\n",
      "\tNumber of valid trials:  92\n",
      "Finished processing subject dataset  2\n",
      "Extracting EDF parameters from /home/inffzy/Desktop/cogs189/cogs189_final_project/data/bci_competition_3_3a_raw/subject3_l1b/bc3_3a_s3.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "#  1, #  2, #  3, #  4, #  5, #  6, #  7, #  8, #  9, # 10, # 11, # 12, # 13, # 14, # 15, # 16, # 17, # 18, # 19, # 20, # 21, # 22, # 23, # 24, # 25, # 26, # 27, # 28, # 29, # 30, # 31, # 32, # 33, # 34, # 35, # 36, # 37, # 38, # 39, # 40, # 41, # 42, # 43, # 44, # 45, # 46, # 47, # 48, # 49, # 50, # 51, # 52, # 53, # 54, # 55, # 56, # 57, # 58, # 59, # 60\n",
      "Creating raw.info structure...\n",
      "Finished processing annotation for subject 3\n",
      "\tTotoal trial count:  240\n",
      "\tRejected trial count:  73\n",
      "\tUnknown cue count:  83\n",
      "\tNumber of valid trials:  84\n",
      "Finished processing subject dataset  3\n"
     ]
    }
   ],
   "source": [
    "subject_dir_names = ['subject1_k3b', 'subject2_k6b', 'subject3_l1b']\n",
    "\n",
    "\n",
    "for idx_subject, subject_dir_name in enumerate(subject_dir_names):\n",
    "    idx_subject += 1\n",
    "    \n",
    "    ## Load subject dataset with MNE\n",
    "    subject_dir = os.path.join(bc3_3a_raw_dir, subject_dir_name)\n",
    "    subject_name = 'bc3_3a_s' + str(idx_subject)\n",
    "    subject_path_gdf = os.path.join(subject_dir, subject_name + '.gdf')\n",
    "    subject_mne = mne.io.read_raw_gdf(subject_path_gdf)\n",
    "    raw_data = subject_mne.get_data()\n",
    "    \n",
    "    X = raw_data.T  # Observations (mixed signal)\n",
    "    ica = FastICA()\n",
    "    S_ = ica.fit_transform(X)  # Recovered signals\n",
    "    A_ = ica.mixing_  # Get estimated mixing matrix\n",
    "    raw_data = S_.T\n",
    "    \n",
    "    \n",
    "    ## Access annotations\n",
    "    annotations = subject_mne.annotations\n",
    "    annotations_list = list(annotations)\n",
    "    \n",
    "    ## Convert annotation dictionary into lists\n",
    "    descriptions = []\n",
    "    onsets = []\n",
    "    onset_trial = -1\n",
    "    valid_trial = True\n",
    "    total_trial_count = 0\n",
    "    rejected_trial_count = 0\n",
    "    unknown_cue_count = 0\n",
    "    \n",
    "    for i in range(len(annotations_list)):\n",
    "        \n",
    "        description_cur = annotations_list[i]['description']\n",
    "        onset_cur = annotations_list[i]['onset']\n",
    "        \n",
    "        if description_cur == '768':\n",
    "            valid_trial = True\n",
    "            onset_trial = onset_cur\n",
    "            total_trial_count += 1\n",
    "            \n",
    "        elif description_cur == '1023':\n",
    "            valid_trial = False\n",
    "            rejected_trial_count += 1\n",
    "            \n",
    "        elif valid_trial: \n",
    "            if description_cur in ['769', '770', '771', '772']:\n",
    "                descriptions.append(int(description_cur))\n",
    "                onsets.append(onset_trial)\n",
    "            elif description_cur == '783':\n",
    "                unknown_cue_count += 1\n",
    "            \n",
    "    descriptions = np.array(descriptions)\n",
    "    onsets = np.array(onsets)\n",
    "    num_valid_trials = onsets.shape[0]\n",
    "    \n",
    "    print('Finished processing annotation for subject', idx_subject)\n",
    "    print('\\tTotoal trial count: ', total_trial_count)\n",
    "    print('\\tRejected trial count: ', rejected_trial_count)\n",
    "    print('\\tUnknown cue count: ', unknown_cue_count)\n",
    "    print('\\tNumber of valid trials: ', num_valid_trials)\n",
    "    \n",
    "    ## Process by onsets to create epochs\n",
    "    \n",
    "    ## Initialize processed data array\n",
    "    processed_motor_imagery_data = np.zeros((num_valid_trials, \n",
    "                                            num_channels,\n",
    "                                            int(motor_imagery_trial_duration * sampling_f)))\n",
    "    \n",
    "    for idx_trial in range(num_valid_trials):\n",
    "        \n",
    "        ## Epoching\n",
    "        onset_time = onsets[idx_trial]\n",
    "        onset_index = int(onset_time * sampling_f)\n",
    "        \n",
    "        motor_imagery_start_time = onset_time + motor_imagery_start        \n",
    "        motor_imagery_start_index = int(motor_imagery_start_time * sampling_f)\n",
    "        motor_imagery_end_index = motor_imagery_start_index + int(motor_imagery_trial_duration * sampling_f)\n",
    "      \n",
    "        motor_imagery_data = raw_data[:, motor_imagery_start_index:motor_imagery_end_index]\n",
    "        \n",
    "        ## DC correction\n",
    "        motor_imagery_data_mean = np.mean(motor_imagery_data, axis=1).reshape((num_channels, 1))\n",
    "        motor_imagery_data = motor_imagery_data - motor_imagery_data_mean\n",
    "        \n",
    "        ## Filtering (band pass to 7~30 Hz)\n",
    "        motor_imagery_data = sosfiltfilt(sos, motor_imagery_data, axis=1)\n",
    "        \n",
    "        ## Baseline correction\n",
    "        baseline_end_index = onset_index + baseline_duration * sampling_f\n",
    "        \n",
    "        baseline_data = raw_data[:, onset_index:baseline_end_index]\n",
    "        baseline_data_mean = np.mean(baseline_data, axis=1).reshape((num_channels, 1))\n",
    "        motor_imagery_data = motor_imagery_data - baseline_data_mean\n",
    "        \n",
    "        ## Store processed motor imagery data\n",
    "        processed_motor_imagery_data[idx_trial, :, :] = motor_imagery_data\n",
    "    \n",
    "    \n",
    "    ## Export processed motor imagery data\n",
    "    processed_subject_path = os.path.join(bc3_3a_processed_dir, subject_name + '_ica.npz')\n",
    "    np.savez(processed_subject_path, \n",
    "             processed_motor_imagery_data=processed_motor_imagery_data, \n",
    "             descriptions=descriptions, \n",
    "             onsets=onsets)\n",
    "    \n",
    "    print('Finished processing subject dataset ', idx_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b66225",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.shape\n",
    "ica = FastICA(n_components=3)\n",
    "S_ = ica.fit_transform(raw_data.T)  # Reconstruct signals\n",
    "A_ = ica.mixing_  # Get estimated mixing matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643480a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = processed_dataset_npz['processed_motor_imagery_data']\n",
    "# new_dataset = []\n",
    "# for i in range(25):\n",
    "#     new_dataset.append(list(dataset[i].flatten()))\n",
    "# new_dataset = np.array(new_dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdfc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced39895",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = processed_dataset_npz[\"descriptions\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed7fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ica = FastICA(n_components=3)\n",
    "S_ = ica.fit_transform(X)  # Reconstruct signals\n",
    "A_ = ica.mixing_  # Get estimated mixing matrix\n",
    "\n",
    "# We can `prove` that the ICA model applies by reverting the unmixing.\n",
    "assert np.allclose(X, np.dot(S_, A_.T) + ica.mean_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b6cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66918031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from scipy import signal\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67257b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "\n",
    "# Number of samples\n",
    "ns = np.linspace(0, 200, 1000)\n",
    "\n",
    "S = np.array([np.sin(ns * 1),\n",
    "              signal.sawtooth(ns * 1.9),\n",
    "              np.random.random(len(ns))]).T\n",
    "\n",
    "# Mixing matrix\n",
    "A = np.array([[0.5, 1, 0.2],\n",
    "              [1, 0.5, 0.4],\n",
    "              [0.5, 0.8, 1]])\n",
    "\n",
    "# Mixed signal matrix\n",
    "X = S.dot(A).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd4c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "S.shape\n",
    "A.shape\n",
    "X.shape\n",
    "ns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474131be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def g_der(x):\n",
    "    return 1 - g(x) * g(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e25de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = ica(X, iterations=10)\n",
    "# actual = mix_sources([s1,s2,s3])\n",
    "# plot_mixture_sources_predictions(X, [s1, s2, s3], S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5c2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f03f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name = 'A01T.gdf'\n",
    "subject_path = os.path.join(bc4_2a_raw_dir, subject_name)\n",
    "subject_mne = mne.io.read_raw_gdf(subject_path)\n",
    "raw_data = subject_mne.get_data()[:22]\n",
    "X = raw_data  # Observations (mixed signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0478afeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8139fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whiten(x):\n",
    "    \n",
    "    # center\n",
    "    mean = np.mean(x, axis=1, keepdims=True)\n",
    "    centered =  x - mean\n",
    "    \n",
    "    # covariance matrix\n",
    "    coVarM = np.cov(centered)\n",
    "\n",
    "    # Single value decomposition\n",
    "    U, S, V = np.linalg.svd(coVarM)\n",
    "\n",
    "    # Calculate diagonal matrix of eigenvalues\n",
    "    d = np.diag(1.0 / np.sqrt(S))\n",
    "\n",
    "    # Calculate whitening matrix\n",
    "    whiteM = np.dot(U, np.dot(d, U.T))\n",
    "\n",
    "    # Project onto whitening matrix\n",
    "    Xw = np.dot(whiteM, X)\n",
    "\n",
    "    return Xw, whiteM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67481eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastIca(signals,  alpha = 1, thresh=1e-8, iterations=1000):\n",
    "    m, n = signals.shape\n",
    "\n",
    "    # Initialize random weights\n",
    "    W = np.random.rand(m, m)\n",
    "\n",
    "    for c in range(m):\n",
    "            w = W[c, :].copy().reshape(m, 1)\n",
    "            w = w / np.sqrt((w ** 2).sum())\n",
    "\n",
    "            i = 0\n",
    "            lim = 100\n",
    "            while ((lim > thresh) & (i < iterations)):\n",
    "\n",
    "                # Dot product of weight and signal\n",
    "                ws = np.dot(w.T, signals)\n",
    "\n",
    "                # Pass w*s into contrast function g\n",
    "                wg = np.tanh(ws * alpha).T\n",
    "\n",
    "                # Pass w*s into g prime\n",
    "                wg_ = (1 - np.square(np.tanh(ws))) * alpha\n",
    "\n",
    "                # Update weights\n",
    "                wNew = (signals * wg.T).mean(axis=1) - wg_.mean() * w.squeeze()\n",
    "\n",
    "                # Decorrelate weights              \n",
    "                wNew = wNew - np.dot(np.dot(wNew, W[:c].T), W[:c])\n",
    "                wNew = wNew / np.sqrt((wNew ** 2).sum())\n",
    "\n",
    "                # Calculate limit condition\n",
    "                lim = np.abs(np.abs((wNew * w).sum()) - 1)\n",
    "\n",
    "                # Update weights\n",
    "                w = wNew\n",
    "\n",
    "                # Update counter\n",
    "                i += 1\n",
    "\n",
    "            W[c, :] = w.T\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88aa0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whiten mixed signals\n",
    "Xw, whiteM = whiten(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = fastIca(Xw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad049855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ica\n",
    "np.dot(W,Xw).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bda553",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d80664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn fastica\n",
    "plt.plot(A_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48022e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
